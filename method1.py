# -*- coding: utf-8 -*-
"""2025-1메인 모델8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HxsQF7iAYinPSqFng25bjEjkmsO44YFv
"""

import torch

print(torch.__version__)                 # 예: '2.1.0+cu121'
print(torch.cuda.is_available())        # ✅ True가 떠야 정상
print(torch.cuda.get_device_name(0))    # 예: 'Tesla T4'

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

from google.colab import drive
drive.mount('/content/drive')

!pip install albumentations

import os
import re
import csv
import random
from glob import glob

import numpy as np
import pandas as pd

from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler
import torchvision.transforms as v2
from torchvision.datasets import ImageFolder
from torch.cuda import empty_cache

import albumentations as A
from albumentations.core.transforms_interface import ImageOnlyTransform
from albumentations.pytorch import ToTensorV2
import torchvision.transforms as T

from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import LabelEncoder

import timm
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from tqdm.cli import tqdm
import cv2
import warnings
warnings.filterwarnings('ignore')

def seed_everything(seed=42):
    random.seed(seed)  # Python 내장 random 모듈
    os.environ['PYTHONHASHSEED'] = str(seed)  # 환경변수 설정
    np.random.seed(seed)  # NumPy
    torch.manual_seed(seed)  # PyTorch CPU 시드 고정
    torch.cuda.manual_seed(seed)  # PyTorch GPU 시드 고정
    torch.cuda.manual_seed_all(seed)  # 멀티 GPU 환경에서도 시드 고정
    torch.backends.cudnn.deterministic = True  # CuDNN 관련 설정
    torch.backends.cudnn.benchmark = False  # 동일한 입력 크기의 데이터가 반복될 경우 속도 향상을 위한 벤치마크 모드 비활성화

# 사용 예시
seed_everything(seed=42)

# 기본 경로 설정
csv_path = "/content/drive/MyDrive/dscover/2025-1메인/ch2025_metrics_train.csv"
image_root = "/content/drive/MyDrive/dscover/2025-1메인/images"
submission_path = "/content/drive/MyDrive/dscover/2025-1메인/ch2025_submission_sample.csv"
submission_df = pd.read_csv(submission_path)

df = pd.read_csv(csv_path)
df = df[~df['sleep_date'].isin(submission_df['sleep_date'])].reset_index(drop=True)
df['data_path'] = df.apply(
    lambda row: f"/content/drive/MyDrive/dscover/2025-1메인/images/"
                f"{row['subject_id']}_images/day_{row['sleep_date']}.png",
    axis=1
)

df.head()

train_df, valid_df = train_test_split(df, test_size = 0.2, random_state=1020)
train_df = train_df.sample(frac=1).reset_index(drop=True)

print(f"count >>> train_set: {len(train_df)}, valid_set: {len(valid_df)}")

# # 상위 이미지 디렉토리
# folder_path = '/content/drive/MyDrive/dscover/2025-1메인/images'

# # 2. 모든 하위 폴더에서 .png 파일 수집
# image_files = []
# for root, dirs, files in os.walk(folder_path):
#     for file in files:
#         if file.endswith(".png"):
#             image_files.append(os.path.join(root, file))

# print(f"총 이미지 수: {len(image_files)}")

# # 3. 무작위로 샘플링 (예: 1000개)
# sample_size = min(1000, len(image_files))
# sampled_files = random.sample(image_files, sample_size)

# # 4. 누적 평균/표준편차 계산
# n_pixels = 0
# sum_pixels = 0.0
# sum_squared_pixels = 0.0

# for file in sampled_files:
#     image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
#     if image is not None:
#         pixels = image.astype(np.float32)
#         n_pixels += pixels.size
#         sum_pixels += np.sum(pixels)
#         sum_squared_pixels += np.sum(pixels ** 2)

# 5. 평균과 표준편차 계산
mean = 3.7926549911499023
std = 28.325054168701172

print(f"Mean: {mean}, Std: {std}")

class RandomHorizontalStrips(ImageOnlyTransform):
    def __init__(self, num_strips=(1, 3), strip_width=84, always_apply=False, p=0.5):
        super(RandomHorizontalStrips, self).__init__(always_apply, p)
        self.num_strips = num_strips
        self.strip_width = strip_width

    def apply(self, img, **params):
        h, w = img.shape[:2]
        num_strips = np.random.randint(self.num_strips[0], self.num_strips[1] + 1)
        for _ in range(num_strips):
            x_start = np.random.randint(0, w - self.strip_width)
            img[:, x_start:x_start + self.strip_width] = 0
        return img

    def get_transform_init_args_names(self):
        return ("num_strips", "strip_width")

    def get_params(self):
        return {"num_strips": self.num_strips, "strip_width": self.strip_width}

mean, std = 0.5, 0.5  # 흑백 이미지이므로 단일 값 사용

train_transforms = A.Compose([
    A.ToGray(p=1.0),                         # RGB → Grayscale
    RandomHorizontalStrips(p=0.5),          # 가로 스트립 추가
    A.Resize(height=224, width=224, p=1),
    A.GaussNoise(p=0.5),
    A.OneOf([
        A.GaussianBlur(p=0.5),
        A.Sharpen(p=0.5)
    ], p=0.5),
    A.Normalize(mean=[mean], std=[std], p=1.0),  # ⚠️ 1채널로 설정
    ToTensorV2()
])

test_transforms = A.Compose([
    A.ToGray(p=1.0),
    A.Resize(always_apply=True, height=224, width=224),
    A.Normalize(mean=[mean], std=[std], p=1.0),
    ToTensorV2()
])

# import torch.nn.functional as F
# from torch.utils.data import random_split

# # 1. 변환 정의 (학습용/검증용 모두 동일하게 grayscale + resize + tensor 변환만)
# transform = T.Compose([
#     T.Grayscale(),
#     T.Resize((224, 224)),
#     T.ToTensor(),
# ])

# # 2. 데이터셋 로드 및 Train/Val 분리 (누수 방지 핵심)
# root_dir = '/content/drive/MyDrive/dscover/2025-1메인/images'
# full_dataset = ImageFolder(root=root_dir, transform=transform)

# val_ratio = 0.2
# val_size = int(len(full_dataset) * val_ratio)
# train_size = len(full_dataset) - val_size

# train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))

# train_loader = DataLoader(train_dataset, batch_size= 16, shuffle=True)
# val_loader = DataLoader(val_dataset, batch_size= 16, shuffle=False)

# class GrayVAE(nn.Module):
#     def __init__(self, latent_dim=64):
#         super().__init__()
#         self.encoder = nn.Sequential(
#             nn.Conv2d(1, 32, 4, 2, 1),  # [B, 32, 112, 112]
#             nn.ReLU(),
#             nn.Conv2d(32, 64, 4, 2, 1), # [B, 64, 56, 56]
#             nn.ReLU(),
#             nn.Conv2d(64, 128, 4, 2, 1),# [B, 128, 28, 28]
#             nn.ReLU(),
#             nn.Flatten()
#         )
#         self.fc_mu = nn.Linear(128*28*28, latent_dim)
#         self.fc_logvar = nn.Linear(128*28*28, latent_dim)

#         self.decoder_fc = nn.Linear(latent_dim, 128*28*28)
#         self.decoder = nn.Sequential(
#             nn.Unflatten(1, (128, 28, 28)),
#             nn.ConvTranspose2d(128, 64, 4, 2, 1), # [B, 64, 56, 56]
#             nn.ReLU(),
#             nn.ConvTranspose2d(64, 32, 4, 2, 1),  # [B, 32, 112, 112]
#             nn.ReLU(),
#             nn.ConvTranspose2d(32, 1, 4, 2, 1),   # [B, 1, 224, 224]
#             nn.Sigmoid()
#         )

#     def encode(self, x):
#         h = self.encoder(x)
#         return self.fc_mu(h), self.fc_logvar(h)

#     def reparameterize(self, mu, logvar):
#         std = torch.exp(0.5 * logvar)
#         eps = torch.randn_like(std)
#         return mu + eps * std

#     def decode(self, z):
#         h = self.decoder_fc(z)
#         return self.decoder(h)

#     def forward(self, x):
#         mu, logvar = self.encode(x)
#         z = self.reparameterize(mu, logvar)
#         x_recon = self.decode(z)
#         return x_recon, mu, logvar

# # 4. VAE 손실 함수
# def vae_loss_function(recon_x, x, mu, logvar):
#     recon_loss = F.mse_loss(recon_x, x, reduction='mean')  # 평균 기반
#     kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
#     return recon_loss + kl_div

# # 5. 학습 루프 (검증 포함)
# device = 'cuda' if torch.cuda.is_available() else 'cpu'
# vae = GrayVAE(latent_dim=64).to(device)
# optimizer = torch.optim.Adam(vae.parameters(), lr=1e-4)

# epochs = 10
# for epoch in range(epochs):
#     vae.train()
#     train_loss = 0
#     for x, _ in train_loader:
#         x = x.to(device)
#         recon_x, mu, logvar = vae(x)
#         loss = vae_loss_function(recon_x, x, mu, logvar)

#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()
#         train_loss += loss.item() * x.size(0)

#     # 검증
#     vae.eval()
#     val_loss = 0
#     with torch.no_grad():
#         for x, _ in val_loader:
#             x = x.to(device)
#             recon_x, mu, logvar = vae(x)
#             loss = vae_loss_function(recon_x, x, mu, logvar)
#             val_loss += loss.item() * x.size(0)

#     print(f"[Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader.dataset):.4f} | Val Loss: {val_loss/len(val_loader.dataset):.4f}")

# # 6. 모델 저장 (누수 방지를 위해 학습 전용 모델만 저장)
# torch.save(vae.state_dict(), 'vae_gray_pretrained2.pt')

# save_path = "/content/drive/MyDrive/dscover/2025-1메인/vae_gray_pretrained2.pt"
# torch.save(vae.state_dict(), save_path)

# VAE 모델 불러오기
vae = GrayVAE(latent_dim=64).to('cuda')
vae.load_state_dict(torch.load('/content/drive/MyDrive/dscover/2025-1메인/vae_gray_pretrained2.pt'))
vae.eval()

from torchvision.transforms import ToPILImage
from albumentations.pytorch import ToTensorV2
import albumentations as A
import numpy as np
import cv2
import torch

def vae_augment(images, vae, noise_std=0.1):
    # 모델은 항상 평가 모드로 (Dropout/BN 등 off)
    vae.eval()

    # 채널/크기 모두 맞춰야 안전
    if images.shape[1:] != (1, 224, 224):
        images = F.interpolate(images, size=(224, 224), mode='bilinear', align_corners=False)

    with torch.no_grad():  # ✅ 그래디언트 추적 방지
        recon, mu, logvar = vae(images)

    # 노이즈 추가 (옵션성 augmentation)
    if noise_std > 0:
        noise = torch.randn_like(recon) * noise_std
        recon = recon + noise
        recon = torch.clamp(recon, 0.0, 1.0)

    return recon

class CustomDataset(Dataset):
    def __init__(self, dataframe, transform=None, is_test=False,
                 use_vae_aug=False, vae=None, noise_std=0.1):
        self.df = dataframe
        self.transform = transform
        self.is_test = is_test
        self.use_vae_aug = use_vae_aug and not is_test  # ✅ test엔 VAE 증강 금지
        self.vae = vae
        self.noise_std = noise_std

        if self.use_vae_aug and self.vae is not None:
            self.vae.eval()  # ✅ Dropout/BN 비활성화

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = row['data_path']

        # ✅ 이미지 로딩 (흑백 + 1채널로 확장)
        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            raise FileNotFoundError(f"Image not found: {img_path}")
        image = np.expand_dims(image, axis=-1)  # (H, W, 1)

        # ✅ transform 적용 (ToTensor 포함)
        if self.transform:
            image = self.transform(image=image)['image']  # torch.Tensor (1, H, W)

        # ✅ VAE 기반 증강 (train만, tensor 상태에서만)
        if self.use_vae_aug and self.vae is not None and isinstance(image, torch.Tensor):
            image = vae_augment(image.unsqueeze(0), self.vae, noise_std=self.noise_std)[0]

        # ✅ 반환
        if self.is_test:
            return image
        else:
            label = torch.tensor(row[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].astype(np.int64).values, dtype=torch.long)
            return image, label

train_dataset = CustomDataset(df, transform=train_transforms, use_vae_aug=True, vae=vae)
valid_dataset = CustomDataset(valid_df, test_transforms,  use_vae_aug=False)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)

epochs = 20

from collections import deque

def run_model(model, loader, loss_fns, optimizer=None, is_training=False, epoch=None, device='cuda'):
    num_labels = len(loss_fns)
    all_targets = [[] for _ in range(num_labels)]
    all_preds = [[] for _ in range(num_labels)]
    smooth_loss_queue = deque(maxlen=50)

    if is_training:
        model.train()
    else:
        model.eval()

    mode = 'Train' if is_training else 'Valid/Test'
    running_loss = 0.0

    bar = tqdm(loader, ascii=True, leave=False)

    context = torch.enable_grad() if is_training else torch.no_grad()  # ✅ 누수 방지 핵심
    with context:
        for cnt, (data, target) in enumerate(bar):
            data = data.to(device, non_blocking=True)
            target = target.to(device, non_blocking=True)

            if is_training:
                optimizer.zero_grad()

            outputs = model(data)  # ✅ forward

            losses = []
            for i in range(num_labels):
                out_i = outputs[i]               # [B, C_i]
                target_i = target[:, i].long()   # [B]

                loss_i = loss_fns[i](out_i, target_i)
                losses.append(loss_i)

                pred_i = torch.argmax(out_i, dim=1)
                all_preds[i].extend(pred_i.cpu().tolist())
                all_targets[i].extend(target_i.cpu().tolist())

            total_loss = sum(losses)
            if is_training:
                total_loss.backward()
                optimizer.step()

            loss_val = total_loss.item()
            running_loss += loss_val
            smooth_loss_queue.append(loss_val)
            smooth_loss = sum(smooth_loss_queue) / len(smooth_loss_queue)

            bar.set_description(f"Epoch {epoch if epoch is not None else '?'} {mode}")
            bar.set_postfix(loss=f"{loss_val:.4f}", smooth=f"{smooth_loss:.4f}")

            # 메모리 누수 방지
            del data, target, outputs, total_loss, losses

    # 메트릭 계산 (누수 없음)
    f1s = [f1_score(all_targets[i], all_preds[i], average='macro') for i in range(num_labels)]
    accs = [accuracy_score(all_targets[i], all_preds[i]) for i in range(num_labels)]

    avg_f1 = sum(f1s) / num_labels
    avg_acc = sum(accs) / num_labels
    return running_loss / len(loader), avg_acc, avg_f1

class MultiHeadResNet(nn.Module):
    def __init__(self, head_classes=[2, 2, 2, 3, 2, 2], pretrained=False):  # ✅ pretrained=False
        super().__init__()
        self.backbone = timm.create_model(
            'resnet18',
            pretrained=pretrained,     # ✅ 흑백 도메인에 pretrained=True는 위험
            in_chans=1,                # ✅ 1채널 입력 (gray)
            num_classes=0,             # ✅ head 제거
            global_pool='avg'          # ✅ 안정적인 global pooling
        )
        in_features = self.backbone.num_features

        self.heads = nn.ModuleList([
            nn.Linear(in_features, c) for c in head_classes
        ])

    def forward(self, x):
        feats = self.backbone(x)  # [B, in_features]
        return [head(feats) for head in self.heads]

import math
from torch.optim.lr_scheduler import _LRScheduler

class CosineAnnealingWarmUpRestarts(_LRScheduler):
    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1.0, last_epoch=-1):
        if not isinstance(T_0, int) or T_0 <= 0:
            raise ValueError("T_0 must be a positive integer")
        if not isinstance(T_mult, int) or T_mult < 1:
            raise ValueError("T_mult must be an integer >= 1")
        if not isinstance(T_up, int) or T_up < 0:
            raise ValueError("T_up must be a non-negative integer")

        self.T_0 = T_0
        self.T_mult = T_mult
        self.T_up = T_up
        self.eta_max = eta_max
        self.base_eta_max = eta_max  # 항상 decay 전 기준값 보관
        self.gamma = gamma

        self.T_i = T_0
        self.cycle = 0
        self.T_cur = last_epoch

        super().__init__(optimizer, last_epoch)

    def get_lr(self):
        if self.T_cur == -1:
            # 초기 상태에서도 base_lr 반환 → 일관성
            return [base_lr for base_lr in self.base_lrs]

        lrs = []
        for base_lr in self.base_lrs:
            if self.T_cur < self.T_up:
                # Warm-up 단계: 선형 증가
                lr = base_lr + (self.eta_max - base_lr) * self.T_cur / max(1, self.T_up)
            else:
                # Cosine decay
                progress = (self.T_cur - self.T_up) / max(1, self.T_i - self.T_up)
                cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))
                lr = base_lr + (self.eta_max - base_lr) * cosine_decay
            lrs.append(lr)
        return lrs

    def step(self, epoch=None):
        if epoch is None:
            self.T_cur += 1
            if self.T_cur >= self.T_i:
                self.cycle += 1
                self.T_cur = self.T_cur - self.T_i
                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up
        else:
            if epoch < self.T_0:
                self.cycle = 0
                self.T_i = self.T_0
                self.T_cur = epoch
            else:
                if self.T_mult == 1:
                    self.cycle = epoch // self.T_0
                    self.T_i = self.T_0
                    self.T_cur = epoch % self.T_0
                else:
                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))
                    self.cycle = n
                    self.T_i = self.T_0 * self.T_mult ** n
                    self.T_cur = epoch - int(self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1))

        # Decay eta_max (따라서 cosine 진폭도 점점 줄어듦)
        self.eta_max = self.base_eta_max * (self.gamma ** self.cycle)

        self.last_epoch = int(epoch if epoch is not None else self.last_epoch + 1)

        # 실제 학습률 적용
        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):
            param_group['lr'] = lr

from torch.utils.data import TensorDataset

head_classes = [2, 2, 2, 3, 2, 2]  # Q1~S3
vae = GrayVAE().to('cuda')
vae.eval()

submission_sample = pd.read_csv("/content/drive/MyDrive/dscover/2025-1메인/ch2025_submission_sample.csv")
submission_pairs = set(
    zip(submission_sample['subject_id'], submission_sample['sleep_date'])
)

# ② train에서 해당 날짜 제거
df_filtered = df[~df[['subject_id', 'sleep_date']].apply(tuple, axis=1).isin(submission_pairs)].reset_index(drop=True)

# ③ 필터링된 df로 CustomDataset 생성
full_dataset = CustomDataset(df_filtered, train_transforms)

k_folds = 3
kf = KFold(n_splits=k_folds, shuffle=True, random_state=1020)
fold_perf = {}

for fold, (train_idx, valid_idx) in enumerate(kf.split(full_dataset)):
    print(f"\n[Fold {fold+1}]")

    train_loader = DataLoader(
        full_dataset, batch_size=16, sampler=SubsetRandomSampler(train_idx),
        num_workers=0, pin_memory=True
    )
    valid_loader = DataLoader(
        full_dataset, batch_size=16, sampler=SubsetRandomSampler(valid_idx),
        num_workers=0, pin_memory=True
    )

    model = MultiHeadResNet(head_classes=head_classes).to('cuda')
    # 클래스별 비율 기반 weight (비율 작을수록 weight 크게)
    weight_q1 = torch.tensor([0.37, 0.63], dtype=torch.float32)
    weight_q2 = torch.tensor([0.50, 0.50], dtype=torch.float32)
    weight_q3 = torch.tensor([0.49, 0.51], dtype=torch.float32)
    weight_s1 = torch.tensor([0.29, 0.16, 0.54], dtype=torch.float32)
    weight_s2 = torch.tensor([0.26, 0.74], dtype=torch.float32)
    weight_s3 = torch.tensor([0.26, 0.74], dtype=torch.float32)

    # GPU에 올리기
    weight_q1 = weight_q1.to('cuda')
    weight_q2 = weight_q2.to('cuda')
    weight_q3 = weight_q3.to('cuda')
    weight_s1 = weight_s1.to('cuda')
    weight_s2 = weight_s2.to('cuda')
    weight_s3 = weight_s3.to('cuda')

    # 🎯 각 target별로 가중치 적용된 criterion 생성
    criterion = [
        nn.CrossEntropyLoss(weight=weight_q1),  # Q1
        nn.CrossEntropyLoss(weight=weight_q2),  # Q2
        nn.CrossEntropyLoss(weight=weight_q3),  # Q3
        nn.CrossEntropyLoss(weight=weight_s1),  # S1
        nn.CrossEntropyLoss(weight=weight_s2),  # S2
        nn.CrossEntropyLoss(weight=weight_s3),  # S3
    ]

    optimizer = optim.AdamW(model.parameters(), lr=5e-4)
    scheduler = CosineAnnealingWarmUpRestarts(
        optimizer, T_0=10, T_mult=2, eta_max=5e-5, T_up=3, gamma=0.5
    )

    best_f1, best_loss = -float('inf'), float('inf')
    best_model_state = None

    for epoch in range(epochs):
        model.train()
        all_train_images = []
        all_train_labels = []

        for images, labels in train_loader:
            images = images.to('cuda')
            labels = labels.to('cuda')
            gray_images = images.mean(dim=1, keepdim=True) # [B, 3, H, W] → [B, 1, H, W]
            aug_images = vae_augment(gray_images, vae, noise_std=0.1)

            combined_images = torch.cat([images, aug_images], dim=0)
            combined_labels = torch.cat([labels, labels], dim=0)

            all_train_images.append(combined_images)
            all_train_labels.append(combined_labels)

        full_inputs = torch.cat(all_train_images, dim=0)
        full_targets = torch.cat(all_train_labels, dim=0)

        train_dataset = TensorDataset(full_inputs, full_targets)
        train_loader_aug = DataLoader(train_dataset, batch_size=16, shuffle=True)

        # 학습
        train_loss, train_acc, train_f1 = run_model(
            model, train_loader_aug, criterion, optimizer,
            is_training=True, epoch=epoch
        )

        # 검증
        with torch.no_grad():
            valid_loss, valid_acc, valid_f1 = run_model(
                model, valid_loader, criterion, optimizer,
                is_training=False, epoch=epoch
            )

        print(
            f"Epoch {epoch+1} | "
            f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f} | "
            f"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f} | Valid F1: {valid_f1:.4f} | "
            f"LR: {optimizer.param_groups[0]['lr']:.2e}"
        )

        if valid_f1 > best_f1:
            best_f1 = valid_f1
            best_loss = valid_loss
            best_model_state = model.state_dict()
            print(f"  🔥 New best model saved for fold {fold+1}")

        scheduler.step()
        empty_cache()

    model_path = f'model_fold_{fold}_f1-{best_f1:.3f}_loss-{best_loss:.3f}.pt'
    torch.save(best_model_state, model_path)
    print(f"✅ Saved: {model_path}")

    fold_perf[fold] = {
        'train_loss': train_loss,
        'train_acc': train_acc,
        'train_f1': train_f1,
        'valid_loss': valid_loss,
        'valid_acc': valid_acc,
        'valid_f1': valid_f1
    }

    del model, optimizer, scheduler, best_model_state
    empty_cache()

from datetime import timedelta
from pathlib import Path
# ------------------ 경로 설정 ------------------
image_root = "/content/drive/MyDrive/dscover/2025-1메인/images"
target_cols = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']
head_classes = [2, 2, 2, 3, 2, 2]

# ✅ sleep_date 기준 이미지 경로 찾기 (오늘 → 7일 전 → 7일 후)
def find_valid_image(row):
    base_date = pd.to_datetime(row['sleep_date'])
    for offset in [0, -7, 7]:
        try_date = (base_date + timedelta(days=offset)).strftime('%Y-%m-%d')
        path = f"{image_root}/{row['subject_id']}_images/day_{try_date}.png"
        if Path(path).exists():
            return path
    return None

# 🔍 이미지 경로 생성
submission_df['data_path'] = submission_df.apply(find_valid_image, axis=1)

# ✅ 이미지가 존재하는 행만 예측 대상으로 추출
has_image_mask = submission_df['data_path'].notna()
image_df = submission_df[has_image_mask].copy()

# ✅ DataLoader 준비
image_dataset = CustomDataset(image_df, transform=test_transforms, is_test=True)
image_loader = DataLoader(image_dataset, batch_size=16, shuffle=False)

# ✅ 모델 로딩
model = MultiHeadResNet(head_classes).to('cuda')
model.load_state_dict(torch.load('model_fold_2_f1-0.466_loss-4.066.pt'))
model.eval()

# ✅ 예측 수행
preds_by_col = [[] for _ in range(6)]
with torch.no_grad():
    for images in tqdm(image_loader, desc="📊 Predicting available images"):
        images = images.to('cuda')
        outputs = model(images)
        for i in range(6):
            preds = torch.argmax(outputs[i], dim=1).cpu().tolist()
            preds_by_col[i].extend(preds)

# ✅ 예측값 image_df에 저장
for i, col in enumerate(target_cols):
    image_df[col] = preds_by_col[i]

# ✅ 원본 submission_df에 반영 (이미지 경로가 있는 행만)
submission_df.update(image_df[target_cols])

# ✅ ID 포맷 정리
submission_df['subject_id'] = submission_df['subject_id'].apply(
    lambda x: f"id{int(str(x).replace('id', '')):02d}"
)

# ✅ 결과 저장
final_submission = submission_df[['subject_id', 'sleep_date', 'lifelog_date'] + target_cols]
final_submission.to_csv("/content/drive/MyDrive/dscover/2025-1메인/submission11.csv", index=False)
print("✅ 제출 완료: submission11.csv 저장됨")

print(pd.Series(predictions[0]).value_counts())

# 대상 컬럼
target_cols = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']

# 각 클래스별 비율 계산
for col in target_cols:
    print(f"\n📊 {col} 클래스 비율:")
    class_counts = df[col].value_counts(normalize=True, dropna=True).sort_index()
    for cls, ratio in class_counts.items():
        print(f"  클래스 {cls}: {ratio * 100:.2f}%")